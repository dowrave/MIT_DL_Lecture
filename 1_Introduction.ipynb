{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.Introduction.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMdgWcWXlCmtiULhajsY4SM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dowrave/MIT_DL_Lecture/blob/main/1_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 220502 MIT 강의"
      ],
      "metadata": {
        "id": "SpFOZ1ZsSEQX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lhbZi02Q3Nm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 내가 궁금해서 넣음 : self & __init__()\n",
        "[참고](https://engineer-mole.tistory.com/190)\n",
        "- self \n",
        "  - 클래스로 인해 호출된 인스턴스 자신을 의미함(인스턴스는 클래스의 속성을 갖고 있는 '객체'이며 클래스 그 자체로는 이용할 수 없음\n",
        "- init\n",
        "  1. 생성자(Constructor) - 초기화 역할\n",
        "  2. 인스턴스화 실시할 때 반드시 처음에 호출되는 특수한 함수\n",
        "  3. 즉, 오브젝트를 생성하고 데이터를 초기화하는 역할이다.\n",
        "- 클래스를 구성할 때 정보를 유지하기 위해 반드시 필요한 구성임\n"
      ],
      "metadata": {
        "id": "wVvKscz2SZA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Super 함수\n",
        "- 상속 관계에서 상속의 대상인 부모 클래스(tf.keras.layers.Layer)를 호출하는 함수\n",
        "- 하위클래스의 이름과 객체가 필요하다"
      ],
      "metadata": {
        "id": "WJ_cr38vRZYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDenseLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(MyDenseLayer, self).__init__()\n",
        "\n",
        "    # Initailize Weights and Bias \n",
        "    self.W = self.add_weight((input_dim, output_dim))\n",
        "    self.b = self.add_weight((1, output_dim))\n",
        "\n",
        "  def call(self, inputs):\n",
        "\n",
        "    # Forward Propagate (가중치 합치고~ 연산하고~)\n",
        "    z = tf.matmul(inputs, self.W) + self.b\n",
        "    output = tf.math.sigmoid(z)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "7wtj0GmDQ-HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 위 클래스의 의미\n",
        "  - 입력층 유닛 수, 출력층 유닛 수만 넣어주면 정의되는 구성임(은닉층 x)"
      ],
      "metadata": {
        "id": "Sz2cVCXPUKnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 위의 클래스는 그냥 다음과 같은 방식으로 구현되어 있음\n",
        "layer = tf.keras.layers.Dense(units = 2) # units : output layer의 유닛 수"
      ],
      "metadata": {
        "id": "37AgjIYLT7IJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 은닉층 삽입\n",
        "- 이 경우 가중치 행렬의 수는 2개가 필요함.\n",
        "  - 입력 -> 은닉층, 은닉 -> 출력층"
      ],
      "metadata": {
        "id": "Z7ofkSN4Uvph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(n), # 당연히 실행 안됨\n",
        "                             tf.keras.layers.Dense(2)\n",
        "])"
      ],
      "metadata": {
        "id": "wDhMLYAZUHbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DNN(은닉층 수가 많아짐)\n",
        "- 수식으로는 시그마 때리면 되겠죠?"
      ],
      "metadata": {
        "id": "dwSmIRY4VYUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 코드에는 Sequential 층을 쌓아주기만 하면 ㅇㅋ\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(n1),\n",
        "                             tf.keras.layers.Dense(n2),\n",
        "                             tf.keras.layers.Dense(n3),\n",
        "                             tf.keras.layers.Dense(n4),\n",
        "                             tf.keras.layers.Dense(n5),\n",
        "                             tf.keras.layers.Dense(2)\n",
        "])"
      ],
      "metadata": {
        "id": "UhN12Zq-VQsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이진분류의 손실 함수(목적 함수)\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, predicted))"
      ],
      "metadata": {
        "id": "2SCDCin-VkHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Numeric(ex : grade) 값을 추출하고 싶을 때(이 2개는 같은 계산을 하는 듯)\n",
        "loss = tf.readuce_mean(tf.square(tf.subtract(y, predicted)))\n",
        "loss = tf.keras.losses.MSE(y, predicted)"
      ],
      "metadata": {
        "id": "vuLiud1oVj-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Descent\n",
        "- GradientTape() : Front Propagation 과정에서의 \"연산 과정\"을 저장, 손실에 대한 미분 값을 계산하기 위해 사용한다.(이게 없다면 연산 결과만이 나타남.)\n"
      ],
      "metadata": {
        "id": "Yreqjr7fb1dL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = tf.Variable([tf.random.normal()])\n",
        "\n",
        "while True:\n",
        "  with tf.GradientTape() as g:\n",
        "    loss = compute_loss(weight) # 이건 딱히 정의 안됐음 ㅎㅎ\n",
        "    gradient = g.gradient(loss, weights) \n",
        "\n",
        "  weights = weights - lr * gradient"
      ],
      "metadata": {
        "id": "g63XtsktVj06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 직접 구현\n"
      ],
      "metadata": {
        "id": "A94GYAhzgKoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model =tf.keras.Sequential([층1, 층2, 층3, ...])\n",
        "\n",
        "# Optimizer 선택 (Adam, Adadelta, Adagrad, RMSProp 등)\n",
        "optimizer = tf.keras.optimizer.SGD()\n",
        "\n",
        "# Loop\n",
        "while True:\n",
        "  prediction = model(x)\n",
        "\n",
        "  with tf.GradientTape() as tape: # tape로 연산 과정 저장\n",
        "    loss = compute_loss(y, prediction)\n",
        "\n",
        "grads = tape.gradient(loss, model.trainable_variables) # 손실에 대한 미분값 계산\n",
        "optimizer.apply_gradients(zip(grads, model.trainable_variables))"
      ],
      "metadata": {
        "id": "MdtEt_cWVjpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MiniBatch\n",
        "- GD는 데이터 전체에 대해 1회 갱신하므로 컴퓨팅 자원이 많이 드는 과정임\n",
        "- SGD는 데이터 1개에 대해 1회 갱신하므로 계산 자체는 의외로 자원이 많이 들지 않지만, 노이즈가 심하고 데이터를 랜덤으로 선택하기 때문에 확률적인 Gradient 추정이기도 함.(극히 소수의 데이터들이 반영되기 때문)\n",
        "- MGD는 GD와 SGD의 중간점임 : 계산이 빠르면서 전체 Gradient를 더 잘 추정함\n",
        "  - 또한 Batch의 Element들은 병렬 처리가 가능하기도 함"
      ],
      "metadata": {
        "id": "f3XZPvgclHvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WLy_UQXFgglx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "p5QosLBVggow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sPuW5w0RggsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nTxRdZPvggt4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}